# Django Configuration
# REQUIRED for production: Generate a strong secret key
# Run: python -c "import secrets; print(secrets.token_hex(32))"
# Note: In DEBUG mode, a random key is generated automatically for development
DJANGO_SECRET_KEY=
# Enable debug mode (DO NOT use in production - setting to 0 requires DJANGO_SECRET_KEY)
DEBUG=0
# Comma-separated list of allowed hosts
ALLOWED_HOSTS=localhost,127.0.0.1
# Optional: Your public URL (e.g., https://subsearch.example.com)
SITE_URL=
# Port to run the application on
PORT=8000
REDDIT_TIMEOUT=10

# Reddit API Credentials
# Get these at: https://www.reddit.com/prefs/apps (create a "script" app)
REDDIT_CLIENT_ID=
REDDIT_CLIENT_SECRET=
# Optional: Reddit account for authenticated searches (higher rate limits)
REDDIT_USERNAME=
REDDIT_PASSWORD=
REDDIT_USER_AGENT=SubSearch/1.0 (self-hosted)

# Redis Configuration (optional - will fallback to memory broker if not available)
REDIS_URL=redis://localhost:6379/0
CELERY_BROKER_URL=redis://localhost:6379/0

# Database (set DB_TYPE to postgres to enable external db, falls back to sqlite)
DB_TYPE=sqlite
SUBSEARCH_DATA_DIR=
SUBSEARCH_DB_PATH=
SUBSEARCH_MAX_CONCURRENT_JOBS=1
# Rate limit delay between API calls (seconds). Lower = faster but may hit rate limits
# Recommended: 0.1-0.15 for authenticated users, 0.2-0.3 for read-only
SUBSEARCH_RATE_LIMIT_DELAY=0.15
SUBSEARCH_PUBLIC_API_LIMIT=2000
SUBSEARCH_PERSIST_BATCH_SIZE=32
SUBSEARCH_JOB_TIMEOUT_SECONDS=3600
# How long before a stuck job is marked as failed (in minutes)
JOB_STALE_THRESHOLD_MINUTES=30

# PostgreSQL Configuration (used when DB_TYPE=postgres)
DB_POSTGRES_HOST=localhost
DB_POSTGRES_PORT=5432
DB_POSTGRES_DB=subsearch
DB_POSTGRES_USER=subsearch
DB_POSTGRES_PASSWORD=
DB_POSTGRES_SSLMODE=prefer

# Auto-ingest controls (uses Celery Beat)
AUTO_INGEST_ENABLED=1
AUTO_INGEST_INTERVAL_MINUTES=180
AUTO_INGEST_LIMIT=1000
AUTO_INGEST_MIN_SUBS=0
AUTO_INGEST_DELAY_SEC=0.25
AUTO_INGEST_KEYWORDS=

# Random dictionary automation (uses Celery Beat)
RANDOM_SEARCH_ENABLED=1
RANDOM_SEARCH_INTERVAL_MINUTES=360
RANDOM_SEARCH_LIMIT=2000
RANDOM_WORD_API=https://random-word-api.vercel.app/api?words=1

# Volunteer node email delivery
NODE_EMAIL_SENDER=
NODE_EMAIL_SENDER_NAME=Sub Search Nodes
NODE_EMAIL_SMTP_HOST=
NODE_EMAIL_SMTP_PORT=587
NODE_EMAIL_SMTP_USERNAME=
NODE_EMAIL_SMTP_PASSWORD=
NODE_EMAIL_USE_TLS=1
NODE_CLEANUP_INTERVAL_SECONDS=86400
NODE_BROKEN_RETENTION_DAYS=7

# Phone-home federation
PHONE_HOME=false
PHONE_HOME_ENDPOINT=https://allthesubs.ericrosenberg.com/api/ingest
PHONE_HOME_TOKEN=
PHONE_HOME_TIMEOUT=10
PHONE_HOME_BATCH_MAX=500
PHONE_HOME_SOURCE=self-hosted

# GitHub Issue Creation (auto-report 5xx errors)
# Create a personal access token at: https://github.com/settings/tokens
# Token needs 'repo' scope for private repos, or 'public_repo' for public repos
GITHUB_TOKEN=
GITHUB_REPO=ericrosenberg1/reddit-sub-analyzer
GITHUB_ISSUE_ENABLED=false
